{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b86b7f4",
   "metadata": {},
   "source": [
    "# Classifying Galaxies Using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c29c47",
   "metadata": {},
   "source": [
    "Around the clock, telescopes affixed to orbital satellites and ground-based observatories are taking millions of pictures of millions upon millions of celestial bodies. These data, of stars, planets and galaxies provide an invaluable resource to astronomers.\n",
    "\n",
    "However, there is a bottleneck: until the data is annotated, it’s incredibly difficult for scientists to put it to good use. Additionally, scientists are usually interested in subsets of the data, like galaxies with unique characteristics.\n",
    "\n",
    "In this project, you will build a neural network to classify deep-space galaxies. You will be using image data curated by Galaxy Zoo, a crowd-sourced project devoted to annotating galaxies in support of scientific discovery.\n",
    "\n",
    "You will identify “odd” properties of galaxies. The data falls into four classes:\n",
    "\n",
    "[1,0,0,0] - Galaxies with no identifying characteristics.\n",
    "Three regular galaxies. Each has a bright center, surrounded by a cloud of stars.\n",
    "\n",
    "[0,1,0,0] - Galaxies with rings.\n",
    "Three ringed galaxies. Each has a bright center, surrounded by a ring of stars.\n",
    "\n",
    "[0,0,1,0] - Galactic mergers.\n",
    "Three photos of galaxies. Each contains two bright orbs surrounded by clouds. These images show galaxies in the process of merging.\n",
    "\n",
    "[0,0,0,1] - “Other,” Irregular celestial bodies.Three photos of irregular celestial objects. Each are irregular clouds. The second has four bright orbs, seemingly suspensed above the cloud of stars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520b7ca",
   "metadata": {},
   "source": [
    "Because the dataset comprises over one thousand images, you’ll use a custom function, load_galaxy_data() to load the compressed data files into the Codecademy learning environment as NumPy arrays. Take a look at the shape of the data.\n",
    "Use .shape to print the dimensions of the input_data and labels.\n",
    "What does the last dimension of the data indicate about the image data? What does the last dimension of the labels indicate about the labels?\n",
    "\n",
    "Next, divide the data into training and validation data, using sklearn’s train_test_split() function.\n",
    "Set the test_size argument to be 0.20.\n",
    "Shuffle the data.\n",
    "Set the random_state to be 222.\n",
    "Set stratify=labels. This ensures that ratios of galaxies in your testing data will be the same as in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data, labels = load_galaxy_data()\n",
    "\n",
    "print(input_data.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_data, labels, test_size=0.20, stratify=labels, shuffle=True, random_state=222)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dfb39c",
   "metadata": {},
   "source": [
    "Now, it’s time to preprocess the input.\n",
    "Define an ImageDataGenerator, and configure it so that the object will normalize the pixels using the rescale parameter.\n",
    "\n",
    "Next, create two NumpyArrayIterators using the .flow(x,y,batch_size=?) method. We recommend using a batch size of 5. Significantly larger batch sizes may cause memory issues on the Codecademy platform.\n",
    "Create a training data iterator by calling .flow() on your training data and labels.\n",
    "Create a validation data iterator by calling .flow() on your training data and labels.\n",
    "\n",
    "\n",
    "\n",
    "Next, build your model, starting with the input shape and output layer.\n",
    "Create a tf.keras.Sequential model named model.\n",
    "Add a tf.keras.Input layer. Refer back to the shape of the data. What should the input shape be?\n",
    "Add a tf.keras.layers.Dense layer as your output layer. Make sure that it outputs 4 features, for the four classes (“Normal”,”Ringed”,”Merger”,”Other”).\n",
    "Remember to use a softmax activation on this final layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028b815",
   "metadata": {},
   "source": [
    "Before you finish designing your architecture, compile your model with an optimizer, loss, and metrics.\n",
    "Use model.compile(optimizer=?,loss=?, metrics=[?,?]) to compile your model.\n",
    "Use tf.keras.optimizers.Adam with a learning_rate of 0.001.\n",
    "Because the labels are one-hot categories, use tf.keras.losses.CategoricalCrossentropy() as your loss.\n",
    "Set [tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.AUC()] as your metrics.\n",
    "\n",
    "\n",
    "Now, let’s go back and finish fleshing out your architecture. An architecture that works well on this task is two convolutional layers, interspersed with max pooling layers, followed by two dense layers:\n",
    "\n",
    "Conv2D: 8 filters, each 3x3 with strides of 2\n",
    "\n",
    "MaxPooling2D: pool_size=(2, 2), strides=2\n",
    "\n",
    "Conv2D: 8 filters, each 3x3 with strides of 2\n",
    "\n",
    "MaxPooling2D: pool_size=(2, 2), strides=2\n",
    "\n",
    "Flatten Layer\n",
    "\n",
    "Hidden Dense Layer with 16 hidden units\n",
    "\n",
    "Output Dense Layer\n",
    "\n",
    "Try coding up this architecture yourself, using:\n",
    "\n",
    "tf.keras.layers.Conv2D\n",
    "\n",
    "tf.keras.layers.MaxPooling2D\n",
    "\n",
    "tf.keras.layers.Flatten()\n",
    "\n",
    "tf.keras.layers.Dense()\n",
    "\n",
    "Don’t forget to use “relu” activations for Dense and Conv2D hidden layers!\n",
    "\n",
    "Use model.summary() to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc054a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_iterator = data_generator.flow(x_train, y_train,batch_size=5)\n",
    "validation_iterator = data_generator.flow(x_valid, y_valid, batch_size=5)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(128, 128, 3)))\n",
    "model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(128, 128, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(8, 3, strides=2, activation=\"relu\")) \n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(8, 3, strides=2, activation=\"relu\")) \n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2,2), strides=(2,2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use model.fit(...) to train your model.\n",
    "The first argument should be your training iterator.\n",
    "Set steps_per_epoch to be the length of your training data, divided by your batch size.\n",
    "Set epochs to be 8.\n",
    "Set validation_data to be your validation iterator.\n",
    "Set validation_steps to be the length of your validation data, divided by your batch size.\n",
    "\n",
    "\n",
    "\n",
    "Now you can run your code to train the model. Training may take a minute or two. After training for twelve epochs, your model’s accuracy should be around 0.60-0.70, and your AUC should fall into the 0.80-0.90 range!\n",
    "What do these results mean?\n",
    "Your accuracy tells you that your model assigns the highest probability to the correct class more than 60% of the time. For a classification task with over four classes, this is no small feat: a random baseline model would achieve only ~25% accuracy on the dataset. Your AUC tells you that for a random galaxy, there is more than an 80% chance your model would assign a higher probability to a true class than to a false one.\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdaa725",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.AUC()])\n",
    "\n",
    "\n",
    "model.fit(\n",
    "        training_iterator,\n",
    "        steps_per_epoch=len(x_train)/5,\n",
    "        epochs=8,\n",
    "        validation_data=validation_iterator,\n",
    "        validation_steps=len(x_valid)/5)\n",
    "\n",
    "\n",
    "from visualize import visualize_activations\n",
    "visualize_activations(model,validation_iterator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
